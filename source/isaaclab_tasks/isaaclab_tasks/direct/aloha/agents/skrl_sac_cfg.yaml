seed: 42


# Models are instantiated using skrl's model instantiator utility
# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html
models:
  separate: True
  policy:  # see gaussian_model parameters
    class: GaussianMixin # CategoricalMixin # 
    clip_actions: True
    clip_log_std: True
    min_log_std: -5.0
    max_log_std: 2.0
    initial_log_std: 0.2
    network:
      - name: net
        input: STATES
        layers: [512]
        activations: elu
    output: tanh(ACTIONS)
  critic_1:  # see deterministic_model parameters
    class: DeterministicMixin
    clip_actions: False
    network:
      - name: net
        input: STATES_ACTIONS
        layers: [512]
        activations: relu
    output: ONE
  critic_2:  # see deterministic_model parameters
    class: DeterministicMixin
    clip_actions: False
    network:
      - name: net
        input: STATES_ACTIONS
        layers: [512, 256]
        activations: elu
    output: ONE
  target_critic_1:  # see deterministic_model parameters
    class: DeterministicMixin
    clip_actions: False
    network:
      - name: net
        input: STATES_ACTIONS
        layers: [512]
        activations: relu
    output: ONE
  target_critic_2:  # see deterministic_model parameters
    class: DeterministicMixin
    clip_actions: False
    network:
      - name: net
        input: STATES_ACTIONS
        layers: [512, 256]
        activations: elu
    output: ONE

memory:
  class: RandomMemory
  memory_size: 1024

agent:
  class: SAC
  gradient_steps: 4
  batch_size: 256

  discount_factor: 0.99
  polyak: 0.005

  random_timesteps: 1024
  learning_starts: 1024

  grad_norm_clip: 0

  learn_entropy: True
  initial_entropy_value: 1
  activate_contact_sensors: True
  state_preprocessor: RunningStandardScaler
  state_preprocessor_kwargs:
    size: auto
    device: "cuda:0"
  # target_entropy: -1.0
  # mixed_precision: True
  # rewards_shaper: 1
  # exploration:
  #   noise: GaussianNoise
  #   noise_kwargs:
  #     mean: 0.0
  #     std: 0.1
  #   initial_scale: 1.0
  #   final_scale: 1.0e-3
  #   timesteps: null

  experiment:
    directory:  'aloha'
    experiment_name: 'SAC'
    write_interval: 200
    checkpoint_interval: 1000


# Sequential trainer
# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html
trainer:
  class: SequentialTrainer
  timesteps: 100000
  environment_info: log